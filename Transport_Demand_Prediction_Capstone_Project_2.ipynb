{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rehmabd/Airbnb-Booking-Analysis/blob/main/Transport_Demand_Prediction_Capstone_Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - EDA/Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### By Abdul Rehman Ansari"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Problem asks us to build a model that predicts the number of seats that\n",
        "Mobiticket can expect to sell for each ride, i.e. for a specific route on a specific date and time.\n",
        "\n",
        "\n",
        "We are provided with Nairobi Transport Data. This is the dataset of tickets\n",
        "purchased from Mobiticket for the 14 routes from “up country” into Nairobi between 17 October 2017 and 20 April 2018. This dataset includes the variables: ride_id, seat_number, payment_method, payment_receipt, travel_date, travel_time,\n",
        "travel_from, travel_to, car_type, max_capacity. There are 14 routes in this dataset. All of the routes end in Nairobi and originate in towns to the North-West of Nairobi towards Lake Victoria.\n",
        "\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This challenge asks you to build a model that predicts the number of seats that Mobiticket can expect to sell for each ride, i.e. for a specific route on a specific date and time. There are 14 routes in this dataset. All of the routes end in Nairobi and originate in towns to the North-West of Nairobi towards Lake Victoria.\n",
        "\n",
        "The towns from which these routes originate are:\n",
        "\n",
        "\n",
        "Awendo\n",
        "\n",
        "\n",
        "Homa Bay\n",
        "\n",
        "\n",
        "Kendu Bay\n",
        "\n",
        "\n",
        "Kijauri\n",
        "\n",
        "Kisii\n",
        "\n",
        "Mbita\n",
        "\n",
        "Migori\n",
        "\n",
        "Ndhiwa\n",
        "\n",
        "Nyachenge\n",
        "\n",
        "Oyugis\n",
        "\n",
        "Rodi\n",
        "\n",
        "Rongo\n",
        "\n",
        "Sirare\n",
        "\n",
        "Sori\n",
        "\n",
        "The routes from these 14 origins to the first stop in the outskirts of Nairobi takes approximately 8 to 9 hours from time of departure. From the first stop in the outskirts of Nairobi into the main bus terminal, where most passengers get off, in Central Business District, takes another 2 to 3 hours depending on traffic.\n",
        "\n",
        "\n",
        "The three stops that all these routes make in Nairobi (in order) are:\n",
        "\n",
        "\n",
        " 1.Kawangware: the first stop in the outskirts of Nairobi\n",
        "\n",
        " 2.Westlands\n",
        "\n",
        "\n",
        " 3 .Afya Centre: the main bus terminal where most passengers disembark\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "All of these points are mapped here.\n",
        "\n",
        "Passengers of these bus (or shuttle) rides are affected by Nairobi traffic not only during their ride into the city, but from there they must continue their journey to their final destination in Nairobi wherever that may be. Traffic can act as a deterrent for those who have the option to avoid buses that arrive in Nairobi during peak traffic hours. On the other hand, traffic may be an indication for people’s movement patterns, reflecting business hours, cultural events, political events, and holidays."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import datetime\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mounting the data set\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CXxbAtvCJeQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "dataset= pd.read_csv('/content/drive/MyDrive/train_revised.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "dataset.head(5)"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "dataset.shape\n"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have 51645 rows and 10 columns."
      ],
      "metadata": {
        "id": "mzJi97TxQkyw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "dataset.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "len(dataset[dataset.duplicated()])"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(dataset.isnull().sum())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# Checking Null Value by plotting Heatmap\n",
        "sns.heatmap(dataset.isnull(), cbar=False)"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset given is a dataset from transport demand ,this dataset includes the variables: ride_id, seat_number, payment_method, payment_receipt, travel_date, travel_time, travel_from, travel_to, car_type, max_capacity. There are 14 routes in this dataset.\n",
        "\n",
        "The above dataset has 51645 rows and 10 columns. There are no missing values and duplicate values in the dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "dataset.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "dataset.describe(include='all')"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style=\"whitegrid\")\n",
        "ax=sns.boxplot(x=dataset[\"max_capacity\"])"
      ],
      "metadata": {
        "id": "5mqarPUHUUQg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ride_id: unique ID of a vehicle on a specific route on a specific day and time.\n",
        "\n",
        "* seat_number: seat assigned to ticket\n",
        "\n",
        "* payment_method: method used by customer to purchase ticket from Mobiticket (cash or Mpesa)\n",
        "\n",
        "* payment_receipt: unique id number for ticket purchased from Mobiticket\n",
        "\n",
        "* travel_date: date of ride departure. (MM/DD/YYYY)\n",
        "\n",
        "* travel_time: scheduled departure time of ride. Rides generally depart on time. (hh:mm)\n",
        "\n",
        "* travel_from: town from which ride originated\n",
        "\n",
        "* travel_to: destination of ride. All rides are to Nairobi.\n",
        "\n",
        "* car_type: vehicle type (shuttle or bus)\n",
        "\n",
        "* max_capacity: number of seats on the vehicle\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in dataset.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",dataset[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Lets find Dependant variable\n",
        "dependant_variable = dataset.groupby(['ride_id'])['seat_number'].count().reset_index()\n",
        "dependant_variable.head()\n",
        "\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop Duplicate rows.\n",
        "dataset= dataset.drop_duplicates(subset='ride_id')"
      ],
      "metadata": {
        "id": "-oSUE--iz8eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "id": "tBtbmCxn0D2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge our dependent variable with our dataset.\n",
        "dataset = dataset.merge(dependant_variable, how=\"left\",on=\"ride_id\")\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "amyh7qNLEMCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# renaming columns.\n",
        "dataset.rename(columns={'seat_number_x':'seat_number','seat_number_y':'number_of_tickets'},inplace= True)\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "uq7MiJPnEQcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "id": "__co0carEVId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.As our target Variable is not available so I calculated it by counting Number of seats on each ride using ride_id and seat_number.\n",
        "\n",
        "2.I remove the  duplicate row, after that merge the dependent variable with our dataset ,and then we can see there are no null values present in dataset.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1-Top 5 places where most people are comming."
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# parameters for pie chart.\n",
        "traffic_from = dataset['travel_from'].value_counts().index\n",
        "traffic_from_val = dataset['travel_from'].value_counts().values"
      ],
      "metadata": {
        "id": "iHvBy4sLcFRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# top 5 places where most people are comming.\n",
        "plt.pie(traffic_from_val[:5], labels=traffic_from[:5], autopct='%1.2f%%')"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " I used Pie chart  to get the percentage comparision of the routes."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most people are travelling from Kisii 59.73%, followed by Rango- 14.60%, kijauri-11%, Migori-7.63%, Homa Bay-7.04% etc."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes , as we can see kisii is most busy and people travel alot in this destination to get business benefit we can focus more on kissi."
      ],
      "metadata": {
        "id": "efyQPfFamBRa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2-Types of payment method"
      ],
      "metadata": {
        "id": "EVaI8ax6RW0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "payment_method = dataset['payment_method'].value_counts()\n",
        "fig = plt.figure(figsize=(10,5))\n",
        "payment_method.plot(kind = \"bar\",color=\"teal\",width=0.3)\n",
        "\n",
        "plt.title('payment method used')\n",
        "plt.ylabel('count')\n",
        "plt.xlabel('payment_type')"
      ],
      "metadata": {
        "id": "ORuxwuBlRW1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "4JaY-ueiRW1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To show the types of cash used in dataset  , I have used Bar Chart"
      ],
      "metadata": {
        "id": "E--jlgddRW1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "9e1FU2SIRW1L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have two types of payment Method Mpesa and cash, people rarely pay Cash.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Z8FOTX8lRW1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3-Types of transport used"
      ],
      "metadata": {
        "id": "CHFRN00Yjc3Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "car_type = dataset['car_type'].value_counts()\n",
        "fig = plt.figure(figsize=(10,5))\n",
        "car_type.plot(kind = 'bar',color=\"purple\",width=0.3)\n",
        "\n",
        "plt.title('Type of Transport used')\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('car_type')"
      ],
      "metadata": {
        "id": "wQUvrAely4sN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####  What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "pU8nl5f5s0_n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Buses have max capacity of bus is 49, whereas max capacity of shuttle is 11."
      ],
      "metadata": {
        "id": "NeQcNm_mHfyh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4-How many tickets sold for each route"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "dataset.columns"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating dataframe to analyse Routes.\n",
        "routes_tickets = dataset.groupby(['travel_from'])['number_of_tickets'].sum().reset_index()\n",
        "routes_tickets\n"
      ],
      "metadata": {
        "id": "NfE82bJxdDuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize']= (16,8)\n",
        "sns.barplot(x= 'travel_from',y= 'number_of_tickets', data= routes_tickets)"
      ],
      "metadata": {
        "id": "urr7Vb04dGIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Bar charts show the frequency counts of values for the different levels of a categorical or nominal variable. Sometimes, bar charts show other statistics, such as percentages.\n",
        "\n",
        "To show the average percentage of tickets sold on routes, I have used Bar Chart."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this plot we can see the Total number of ticket sold for each Routes.\n",
        "\n",
        "we can see that Kisii has most number of tickets sold."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5-Distribution of number of tickets"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# Distribution of number of tickets\n",
        "plt.rcParams['figure.figsize']= (15,8)\n",
        "sns.scatterplot(x= 'travel_from',y= 'number_of_tickets', data= dataset)"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "A scatter plot (aka scatter chart, scatter graph) uses dots to represent values for two different numeric variables. The position of each dot on the horizontal and vertical axis indicates values for an individual data point. Scatter plots are used to observe relationships between variables.\n",
        "\n",
        "Thus, I have used the scatter plot to depict the distribution of tickets."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In above scatter plot we can see the distribution of number of tickets in different Routes.In that migori has the highest number of tickets sold and follow by sirare and other routes."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8 - Heat Map"
      ],
      "metadata": {
        "id": "U8rMMIZBzSiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "corr = dataset.corr()\n",
        "cmap = cmap=sns.diverging_palette(5, 250, as_cmap=True)\n",
        "\n",
        "def magnify():\n",
        "    return [dict(selector=\"th\",\n",
        "                 props=[(\"font-size\", \"7pt\")]),\n",
        "            dict(selector=\"td\",\n",
        "                 props=[('padding', \"0em 0em\")]),\n",
        "            dict(selector=\"th:hover\",\n",
        "                 props=[(\"font-size\", \"12pt\")]),\n",
        "            dict(selector=\"tr:hover td:hover\",\n",
        "                 props=[('max-width', '200px'),\n",
        "                        ('font-size', '12pt')])\n",
        "]\n",
        "\n",
        "corr.style.background_gradient(cmap, axis=1)\\\n",
        "    .set_properties(**{'max-width': '80px', 'font-size': '10pt'})\\\n",
        "    .set_caption(\"Hover to magify\")\\\n",
        "    .set_precision(2)\\\n",
        "    .set_table_styles(magnify())"
      ],
      "metadata": {
        "id": "Jq7QmpD9Wsrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correlation matrix is a table showing correlation coefficients between variables. Each cell in the table shows the correlation between two variables. A correlation matrix is used to summarize data, as an input into a more advanced analysis, and as a diagnostic for advanced analyses. The range of correlation is [-1,1].\n",
        "\n",
        "Thus to know the correlation between all the variables along with the correlation coeficients, i used correlation heatmap.\n",
        "\n",
        "As we can see from the above correlation heatmap the columns  are positiveliy highly correlated with a value of 1.\n"
      ],
      "metadata": {
        "id": "Wixuu7EJG0tx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Most number of tickets are sold from same route.\n",
        "\n",
        "2.The number of buses used in traveling is same as the number of shuttle used.\n",
        "\n",
        "3.There are no travellers who pay in cash."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most number of tickets are sold  from same route.\n",
        "\n",
        "Null Hypothesis : Most number of tickets are sold from same route.\n",
        "\n",
        "\n",
        "Alternative Hypothesis : Most number of tickets are not sold from same route."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x='travel_from',y='number_of_tickets', palette='viridis',data=dataset)\n",
        "plt.xticks(rotation=90)\n",
        "plt.title('Total tickets from each origin place')\n",
        "plt.xlabel('Origin Place')\n",
        "plt.ylabel('Number of Tickets')\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above we can see, tickets are sold in every route , hence we can reject null hypothesis"
      ],
      "metadata": {
        "id": "wj9qpr9zvRDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statement: The number of buses used in traveling is same as the number of shuttle used. Let Number of buses used be Nob, and Number of shuttle used be Nos\n",
        "\n",
        "Null Hypothesis (H0) : Nob = Nos\n",
        "\n",
        "Arlternative Hypothesis (Ha) : Nob != Nos"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "car_type = dataset['car_type'].value_counts()\n",
        "fig = plt.figure(figsize=(8,5))\n",
        "car_type.plot(kind = 'bar',color=\"teal\",width=0.2)\n",
        "\n",
        "plt.title('Type of Transport used')\n",
        "plt.ylabel('Count')\n",
        "plt.xlabel('car_type')"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above, Nob > Nos, hence we can reject Null Hypothesis."
      ],
      "metadata": {
        "id": "USxyJOLtwb44"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no travellers who pay in cash. Let number of travellers pay in cash be Na.\n",
        "\n",
        "Null Hypothesis (H0) : Na = 0 (No traveller pay in cash)\n",
        "\n",
        "Alternative Hypothesis (Ha) : Na != 0"
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "payment_method = dataset['payment_method'].value_counts()\n",
        "fig = plt.figure(figsize=(10,5))\n",
        "payment_method.plot(kind = \"bar\",color=\"teal\",width=0.3)\n",
        "\n",
        "plt.title('payment method used')\n",
        "plt.ylabel('count')\n",
        "plt.xlabel('payment_type')"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above we can see that payment is made by mpesa , there are no travellers who pay in cash\n",
        "\n",
        "Hence Na = 0, therefore we cannot reject Null Hypothesis"
      ],
      "metadata": {
        "id": "pwLCyiENyhgs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "print(dataset.isnull().sum())"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no missing values to handle in the given dataset."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lc5_kgznBSst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Data Transformation"
      ],
      "metadata": {
        "id": "LfVSAA1VzRmY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets convert  teavel_date and travel_time columns to datetime format.\n",
        "dataset[\"travel_date\"]=pd.to_datetime(dataset[\"travel_date\"])\n",
        "dataset['travel_time']=pd.to_datetime(dataset[\"travel_time\"])"
      ],
      "metadata": {
        "id": "Y7j9LjOxzRmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets extract the important features from teavel_date and travel_time columns.\n",
        "dataset[\"day_of_week\"]=dataset[\"travel_date\"].dt.dayofweek\n",
        "dataset[\"day_of_year\"]=dataset[\"travel_date\"].dt.dayofyear\n",
        "dataset[\"day_of_month\"]=dataset[\"travel_date\"].dt.day\n",
        "dataset[\"is_weekend\"]=dataset[\"day_of_week\"].apply( lambda x : 1 if x  in [5,6] else 0 )\n",
        "dataset[\"hour\"]=dataset[\"travel_time\"].dt.hour\n",
        "dataset[\"minute\"]=dataset[\"travel_time\"].dt.minute\n",
        "dataset[\"month\"]=dataset[\"travel_date\"].dt.month"
      ],
      "metadata": {
        "id": "IS5nqTpIzRmi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "x21pKMF2zRmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scatter plot to understand day of month relation with number of tickets.\n",
        "plt.rcParams['figure.figsize']= (10,6)\n",
        "sns.scatterplot(x=dataset['day_of_month'],y= dataset['number_of_tickets'])"
      ],
      "metadata": {
        "id": "7eME38JQzRmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* We can see that there is the gap between 5 to 11 in the day of the month. We can assume that there is official holiday of public transport between these days. we can also say that the number of tickets in all the days of month are same."
      ],
      "metadata": {
        "id": "AeVw6WQ5kh64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scatter plot to understand hour relation with number of tickets.\n",
        "plt.rcParams['figure.figsize']= (15,8)\n",
        "sns.scatterplot(x=dataset['hour'],y= dataset['number_of_tickets'])"
      ],
      "metadata": {
        "id": "AzyVEV1e8LuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* We can see that most of the ticktes were sold at 7 AM and 8 PM. And that seems true because in the morning most of the people go to the work and office.\n",
        "\n",
        "* From the above we can say that there is not ride between 12pm to 5.30Pm"
      ],
      "metadata": {
        "id": "3MGz5bi-KYXK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's add distance and time taken column in our dataset using Google Maps.**"
      ],
      "metadata": {
        "id": "fHdsAN3_5Q52"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "#calculating distance between two points using google maps.\n",
        "distance = {'Migori': 370 , 'Keroka': 280, 'Homa Bay':360, 'Kisii':305.1, 'Keumbu':295, 'Rongo':332,\n",
        "'Kijauri':271, 'Oyugis':330.6, 'Awendo':351, 'Sirare':392, 'Nyachenge':326, 'Kehancha': 387.7,\n",
        "'Kendu Bay':347, 'Sori':399, 'Rodi':348, 'Mbita':401, 'Ndhiwa': 371}\n",
        "dataset[\"distance\"]=dataset.travel_from.map(distance)"
      ],
      "metadata": {
        "id": "hNsDC2hVzRmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculating travel time between two points using google maps.\n",
        "#  7*60 is converting hours into minutes.\n",
        "time = {'Migori': 7*60+8 , 'Keroka': 5*60, 'Homa Bay':7*60, 'Kisii':5*60+34, 'Keumbu':5*60+20, 'Rongo':6*60+21,\n",
        "'Kijauri':60*4+50,'Oyugis':5*60+50, 'Awendo':6*60+38, 'Sirare':7*60+30, 'Nyachenge':6*60+10, 'Kehancha':7*60+10,\n",
        "'Kendu Bay':6*60+10, 'Sori':7*60+30, 'Rodi':6*60+40, 'Mbita':7*60+23, 'Ndhiwa': 7*60}\n",
        "dataset[\"time_taken\"]=dataset.travel_from.map(time)"
      ],
      "metadata": {
        "id": "tFpX6LPJzRml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "v5CwGqCw6LHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulating Features to minimize feature correlation and create new features\n",
        "#lets see correlation of distance, time taken and number of tickets.\n",
        "corr_columns = dataset[['distance','time_taken','number_of_tickets']]"
      ],
      "metadata": {
        "id": "62Zr50yCkthj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correlation = corr_columns.corr()\n",
        "sns.heatmap(abs(correlation), annot=True, cmap='coolwarm')"
      ],
      "metadata": {
        "id": "YI_l5HCQmisP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that distance and time_taken column have strong **Multicollinearity** with each other. so we have to do something about it.\n",
        "\n",
        "we know that Speed = Distance/Time so we will use it and drop distance and time_taken."
      ],
      "metadata": {
        "id": "Sx57WGWDA7fC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "eEEEZCiRlYLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create speed column.\n",
        "dataset['speed']= dataset['distance']/dataset['time_taken']"
      ],
      "metadata": {
        "id": "R9RPeCiMmpmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "kaMpcWZSmv1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize']= (10,8)\n",
        "sns.barplot(x= 'time_taken',y= 'number_of_tickets', data= dataset)"
      ],
      "metadata": {
        "id": "Ub-jKxhM08ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize']= (10,8)\n",
        "sns.scatterplot(x= 'distance',y= 'number_of_tickets', data= dataset)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7ql09cxanBh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# coverting categorical features into Numerical.\n",
        "dataset = pd.get_dummies(dataset, columns=['travel_from','car_type'], drop_first=True)"
      ],
      "metadata": {
        "id": "cuO6vdEC4TMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "id": "B_Dh1EtI4ZAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_data = dataset.copy()"
      ],
      "metadata": {
        "id": "au-28ltL4dAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear_data.columns"
      ],
      "metadata": {
        "id": "HfhKPHDB4hhS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unnecessary_cols = ['ride_id', 'seat_number', 'payment_method', 'payment_receipt',\n",
        "       'travel_date', 'travel_time','number_of_tickets', 'distance', 'time_taken', 'travel_to']"
      ],
      "metadata": {
        "id": "3nyUGhr14lWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing required libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score\n",
        "import math"
      ],
      "metadata": {
        "id": "mPfCZMz2-yHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating function for evaluation metrics\n",
        "def evaluate_metric(actual,predicted):\n",
        "  print('MSE is {}'.format(mean_squared_error(actual, predicted)))\n",
        "  print('RMSE is {}'.format(math.sqrt(mean_squared_error(actual, predicted))))\n",
        "  print('MAE is {}'.format(mean_absolute_error(actual, predicted)))\n",
        "  print('MAPE is {}'.format(np.mean(np.abs((actual - predicted) / actual)) * 100))\n",
        "  print('R2 Score is {}'.format(r2_score(actual, predicted)))"
      ],
      "metadata": {
        "id": "o29xvC1U-0RH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1 - Implementing Linear Regression"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "X= linear_data.drop(unnecessary_cols, axis='columns')\n",
        "Y= linear_data['number_of_tickets']"
      ],
      "metadata": {
        "id": "UWtCHR4Ezc_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.3, random_state=50)\n",
        "reg = LinearRegression()\n",
        "\n",
        "# fitting linear model\n",
        "reg.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ua6sT0cKoAN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train = reg.predict(X_train)\n",
        "y_pred = reg.predict(X_test)"
      ],
      "metadata": {
        "id": "gr9RB-HFoF4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score_test = r2_score(y_test,y_pred)\n",
        "print('r2_score:',r2_score_test)\n",
        "\n",
        "adj_r2=1-(1-r2_score(y_test, y_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1))\n",
        "print('Adjusted r2_score :',adj_r2)"
      ],
      "metadata": {
        "id": "6HOLkC3joHxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Model score on Train and Test\n",
        "train_model = reg.score(X_train,y_train)\n",
        "print('Training Accuracy:',train_model)\n",
        "\n",
        "test_model = reg.score(X_test,y_test)\n",
        "print('Testing Accuracy:',test_model)"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test dataset Matrics\n",
        "MSE  = mean_squared_error(y_test,y_pred)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "MAE = mean_absolute_error(y_test,y_pred)\n",
        "print('MAE :' ,MAE)\n",
        "\n",
        "MAPE = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "print('MAPE :',MAPE)"
      ],
      "metadata": {
        "id": "LcJ4L2lOoqEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I used linear regression algorithm to create the model. As I got not so good result.**"
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 - Random Forest Regressor"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "random_forest_data = dataset.copy()\n",
        "\n",
        "# multicollinearity does not affect Tree based model so we will include distance and time take.\n",
        "unnecessary_cols = ['ride_id', 'seat_number', 'payment_method', 'payment_receipt',\n",
        "       'travel_date', 'travel_time','number_of_tickets', 'travel_to']"
      ],
      "metadata": {
        "id": "63y_N-PVpDP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = random_forest_data.drop(unnecessary_cols, axis='columns')\n",
        "Y= random_forest_data['number_of_tickets']\n",
        "\n",
        "\n",
        "#train and test split\n",
        "X_train , X_test, y_train, y_test = train_test_split(X,Y, test_size= 0.3, random_state=0 )"
      ],
      "metadata": {
        "id": "ns27BKLZp-SU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_reg = RandomForestRegressor()"
      ],
      "metadata": {
        "id": "kg4vuqoYqHFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the Algorithm\n",
        "random_reg.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "7h2HPeoKqIX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "y_pred = random_reg.predict(X_test)"
      ],
      "metadata": {
        "id": "eEWBfF8LqJnu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Model score on Train and Test\n",
        "train_model = random_reg.score(X_train,y_train)\n",
        "print('Training Accuracy:',train_model)\n",
        "\n",
        "test_model = random_reg.score(X_test,y_test)\n",
        "print('Testing Accuracy:',test_model)"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score_test = r2_score(y_test,y_pred)\n",
        "print('r2_score:',r2_score_test)\n",
        "\n",
        "adj_r2=1-(1-r2_score(y_test, y_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1))\n",
        "print('Adjusted r2_score :',adj_r2)"
      ],
      "metadata": {
        "id": "-RzAIi1mqjdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test dataset Matrics\n",
        "MSE  = mean_squared_error(y_test,y_pred)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "MAE = mean_absolute_error(y_test,y_pred)\n",
        "print('MAE :' ,MAE)\n",
        "\n",
        "MAPE = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "print('MAPE :',MAPE)"
      ],
      "metadata": {
        "id": "CbRWqua1qpWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Our model seem to overfit lets do hyperperemeter tuning using GridSearch and RandomSearchCV.**"
      ],
      "metadata": {
        "id": "mjX6apVHML1W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "metadata": {
        "id": "bjbUYqI7BNZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques GridSearch CV and RandomSearch CV.\n",
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = [ 'sqrt','log2']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 1000,10)]\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10,14]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4,6,8]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "              'criterion':['squared_error','absolute_error','poisson']}\n",
        "print(random_grid)"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = RandomForestRegressor()\n",
        "random = RandomizedSearchCV( estimator=estimator, param_distributions=random_grid, n_iter=3, cv=2, verbose=1,\n",
        "                               random_state=0 )"
      ],
      "metadata": {
        "id": "_l8ycxLWrPdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the Algorithm\n",
        "random.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "fz3XmgEQrULs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "random.best_params_"
      ],
      "metadata": {
        "id": "BdvQvHI5feWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Now lets use GridSearchCV on this best parameters.**"
      ],
      "metadata": {
        "id": "ZtFTGgwEq7ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "Zj_-9JIXrFrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_grid ={'criterion': ['squared_error'],\n",
        " 'max_depth':[655,660,670],\n",
        " 'max_features': ['log2'],\n",
        " 'min_samples_leaf':[6],\n",
        " 'min_samples_split': [5],\n",
        " 'n_estimators': [550,650,600]}"
      ],
      "metadata": {
        "id": "-e3lAqzdrFc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = RandomForestRegressor()\n",
        "grid = GridSearchCV( estimator=estimator, param_grid =random_grid, cv=2, verbose=1\n",
        "                               ,n_jobs=-1 )"
      ],
      "metadata": {
        "id": "WfTBF9MerFQt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid.fit(X,Y)"
      ],
      "metadata": {
        "id": "yr-8hRZ4rFD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid.best_params_"
      ],
      "metadata": {
        "id": "G5SVQ2UlrEfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = grid.predict(X_test)"
      ],
      "metadata": {
        "id": "iSlUPsVurVWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model score on Train and Test\n",
        "train_model = grid.score(X_train,y_train)\n",
        "print('Training Accuracy:',train_model)\n",
        "\n",
        "test_model = grid.score(X_test,y_test)\n",
        "print('Testing Accuracy:',test_model)"
      ],
      "metadata": {
        "id": "E3esRjSXrVS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score_test = r2_score(y_test,y_pred)\n",
        "print('r2_score:',r2_score_test)\n",
        "\n",
        "adj_r2=1-(1-r2_score(y_test, y_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1))\n",
        "print('Adjusted r2_score :',adj_r2)"
      ],
      "metadata": {
        "id": "SrFbA4-YrVKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test dataset Matrics\n",
        "MSE  = mean_squared_error(y_test,y_pred)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "MAE = mean_absolute_error(y_test,y_pred)\n",
        "print('MAE :' ,MAE)\n",
        "\n",
        "MAPE = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "print('MAPE :',MAPE)"
      ],
      "metadata": {
        "id": "XS9MSWoXriK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used GridSearchCV and RandomizedSearchCV to tune hyperparameter. The best fit values are found out to be :{'n_estimators': 1200,\n",
        " 'max_depth': 450} and for GridSearchCV {'max_depth': 660, 'n_estimators': 550}"
      ],
      "metadata": {
        "id": "zUoLswdfqO73"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By using GridSearchCV, the training accuracy have increase slightly, but the test accuracy has increased a lot, hence, the problem of overfitting which was faced in train_test_split method is removed."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 - XGboost"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "import xgboost as xgb\n",
        "# multicollinearity does not affect Tree based model so we will include distance and time take.\n",
        "unnecessary_cols = ['ride_id', 'seat_number', 'payment_method', 'payment_receipt',\n",
        "       'travel_date', 'travel_time','number_of_tickets', 'travel_to']"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgboost_data = dataset.copy()"
      ],
      "metadata": {
        "id": "NXv7m_V_tQGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = xgboost_data.drop(unnecessary_cols, axis=1)\n",
        "Y = xgboost_data['number_of_tickets']\n",
        "\n",
        "#train and test split\n",
        "X_train , X_test, y_train, y_test = train_test_split(X,Y, test_size= 0.3, random_state=0 )\n"
      ],
      "metadata": {
        "id": "qAXW0-we0gfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the Algorithm\n",
        "xgb_reg = xgb.XGBRegressor(\n",
        "                        booster= 'gbtree',\n",
        "                        eta= 0.004,\n",
        "                        learning_rate= 0.1,\n",
        "                        max_depth= 7,\n",
        "                        min_child_weight= 10,\n",
        "                        n_jobs= 1,\n",
        "                        objective= 'reg:linear',\n",
        "                        random_state= 0,\n",
        "                        scale_pos_weight= 1,\n",
        "                        verbosity= 1)\n",
        "\n",
        "xgb_reg.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "IxZR80YV1mBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "y_pred = xgb_reg.predict(X_test)"
      ],
      "metadata": {
        "id": "Fv9imWr6tPBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Model score on Train and Test\n",
        "train_model = xgb_reg.score(X_train,y_train)\n",
        "print('Training Accuracy:',train_model)\n",
        "\n",
        "test_model = xgb_reg.score(X_test,y_test)\n",
        "print('Testing Accuracy:',test_model)"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score_test = r2_score(y_test,y_pred)\n",
        "print('r2_score:',r2_score_test)\n",
        "\n",
        "adj_r2=1-(1-r2_score(y_test, y_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1))\n",
        "print('Adjusted r2_score :',adj_r2)"
      ],
      "metadata": {
        "id": "KOQ1ZmaPuWLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test dataset Matrics\n",
        "MSE  = mean_squared_error(y_test,y_pred)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "MAE = mean_absolute_error(y_test,y_pred)\n",
        "print('MAE :' ,MAE)\n",
        "\n",
        "MAPE = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "print('MAPE :',MAPE)"
      ],
      "metadata": {
        "id": "BagBd1mtuZyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our XGboost model seem to over fit lets GridSearchCV to try multiple Parameters."
      ],
      "metadata": {
        "id": "4cByoCetx9V7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "kLLExXopu6RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques  (GridSearch CV)\n",
        "xgb = xgb.XGBRegressor()"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\"min_child_weight\":[9,10,11],\n",
        "          'eta': [0.05,0.06,0.07],\n",
        "          'eval_metric':['rmse'],\n",
        "          'colsample_bytree':[0.6],\n",
        "          'max_depth': [8,9,10],\n",
        "          }"
      ],
      "metadata": {
        "id": "SzO1qYIHvRyg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the Algorithm\n",
        "xgb_grid = GridSearchCV(xgb,param_grid=params, verbose=1,cv=5)\n",
        "xgb_grid.fit(X, Y)"
      ],
      "metadata": {
        "id": "U_8GVPN5vc7H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_grid.best_params_"
      ],
      "metadata": {
        "id": "syCJ-7qzv6OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_grid.best_estimator_.get_params()"
      ],
      "metadata": {
        "id": "9pLUdN1Kv-BU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "y_pred = xgb_grid.predict(X_test)"
      ],
      "metadata": {
        "id": "WEb1UfKRv8oE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model score on Train and Test\n",
        "train_model = xgb_grid.score(X_train,y_train)\n",
        "print('Training Accuracy:',train_model)\n",
        "\n",
        "test_model = xgb_grid.score(X_test,y_test)\n",
        "print('Testing Accuracy:',test_model)"
      ],
      "metadata": {
        "id": "Mk9wZmKkwPNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r2_score_test = r2_score(y_test,y_pred)\n",
        "print('r2_score:',r2_score_test)\n",
        "\n",
        "adj_r2=1-(1-r2_score(y_test, y_pred))*((X_test.shape[0]-1)/(X_test.shape[0]-X_test.shape[1]-1))\n",
        "print('Adjusted r2_score :',adj_r2)"
      ],
      "metadata": {
        "id": "b6dJE2suwnr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test dataset Matrics\n",
        "MSE  = mean_squared_error(y_test,y_pred)\n",
        "print(\"MSE :\" , MSE)\n",
        "\n",
        "RMSE = np.sqrt(MSE)\n",
        "print(\"RMSE :\" ,RMSE)\n",
        "\n",
        "MAE = mean_absolute_error(y_test,y_pred)\n",
        "print('MAE :' ,MAE)\n",
        "\n",
        "MAPE = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
        "print('MAPE :',MAPE)"
      ],
      "metadata": {
        "id": "evKVt9gQwpOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV which uses the Grid Search technique for finding the optimal hyperparameters to increase the model performance.\n",
        "\n",
        "\n",
        "In GridSearchCV, along with Grid Search, cross-validation is also performed. Cross-Validation is used while training the model.\n",
        "\n",
        "That's why I have used GridsearCV method for hyperparameter optimization"
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By using GridSearchCV, the test accuracy has increased a lot, hence, the problem of overfitting which was faced in train_test_split method is removed."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following evalutation metrics were chosen:\n",
        "\n",
        "1.Mean Squared Error (MSE)\n",
        "\n",
        "2.Root Mean Squared Error (RMSE)\n",
        "\n",
        "3.Mean Absolute Error (MAE)\n",
        "\n",
        "4.Mean Absolute Percentage Error (MAPE)\n",
        "\n",
        "5.R2 Score\n",
        "\n",
        "6.Adjusted R2 Score\n",
        "\n"
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Xgboost regression model performed the best among them.\n",
        "Random forest and XG Boost perform almost same.\n",
        "\n",
        "Final Prediction Model :Xgboost regression model  (GridSearchCV)\n",
        "\n",
        "Performance on test data:\n",
        "\n",
        "r2_score: 0.741171136950983\n",
        "\n",
        "Adjusted r2_score : 0.7372452387032189"
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# arry of important features\n",
        "importance = xgb_grid.best_estimator_.feature_importances_\n",
        "importance"
      ],
      "metadata": {
        "id": "nl7NKwqjzjYB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting important features using Xgboost in built function.\n",
        "plt.figure(figsize=(12,10))\n",
        "sorted_idx = xgb_grid.best_estimator_.feature_importances_.argsort()\n",
        "plt.barh(X.columns[sorted_idx],importance[sorted_idx])\n",
        "plt.xlabel('Xgboost Feature Importance')"
      ],
      "metadata": {
        "id": "akmbjLlp3vVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* As we have implemented three different models to predict the number of seats that Mobiticket can expect to sell for each ride. Linear Regression, Random Forest Regressor and Xgboost Regressor.Before Hyperparameter tuning Random Forest and Xgboost gave us accuracy score of around 60 to 65% but after\n",
        "using Hyperparameter tuning Random Forest gave us\n",
        "Accuracy score of 66% and Xgboost gave us accuracy score of\n",
        "around 79 to 80%.\n",
        "\n",
        "* Xgboost regression model performed the best among them.\n",
        "Our Model will help Mobiticket and Bus operators to anticipate the number of tickets they can expect to sell for each ride.\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}